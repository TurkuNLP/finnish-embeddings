"""
TASK_PROMPTS
    These are a combination from
    https://github.com/QwenLM/Qwen3-Embedding/blob/main/evaluation/task_prompts.json and
    https://github.com/microsoft/unilm/blob/9c0f1ff7ca53431fe47d2637dfe253643d94185b/e5/utils.py#L106
    where only the unique task descriptions are kept, and the task name is the first encountered task name with that description.

CUSTOM_PROMPTS
    These are customized for the given task.

MTEB_PROMPTS
    https://github.com/embeddings-benchmark/mteb/tree/main
    These contain unique task descriptions from MTEB, grouped by the task type. Name of the task is the first encountered task with a given description,
    but other tasks with the same description may exist.

MTEB_PROMPTS_FLAT
    Same MTEB prompts but with flat dictionary structure (= no grouping by task type).
"""

TASK_PROMPTS = {
    "AmazonCounterfactualClassification": "Classify a given Amazon customer review text as either counterfactual or not-counterfactual",
    "AmazonPolarityClassification": "Classify Amazon reviews into positive or negative sentiment",
    "AmazonReviewsClassification": "Classify the given Amazon review into its appropriate rating category",
    "Banking77Classification": "Given a online banking query, find the corresponding intents",
    "EmotionClassification": "Classify the emotion expressed in the given Twitter message into one of the six emotions: anger, fear, joy, love, sadness, and surprise",
    "ImdbClassification": "Classify the sentiment expressed in the given movie review text from the IMDB dataset",
    "MassiveIntentClassification": "Given a user utterance as query, find the user intents",
    "MassiveScenarioClassification": "Given a user utterance as query, find the user scenarios",
    "MTOPDomainClassification": "Classify the intent domain of the given utterance in task-oriented conversation",
    "MTOPIntentClassification": "Classify the intent of the given utterance in task-oriented conversation",
    "ToxicConversationsClassification": "Classify the given comments as either toxic or not toxic",
    "TweetSentimentExtractionClassification": "Classify the sentiment of a given tweet as either positive, negative, or neutral",
    "TNews": "Classify the fine-grained category of the given news title",
    "IFlyTek": "Given an App description text, find the appropriate fine-grained category",
    "MultilingualSentiment": "Classify sentiment of the customer review into positive, neutral, or negative",
    "JDReview": "Classify the customer review for iPhone on e-commerce platform into positive or negative",
    "OnlineShopping": "Classify the customer review for online shopping into positive or negative",
    "Waimai": "Classify the customer review from a food takeaway platform into positive or negative",
    "ArxivClusteringP2P": "Identify the main and secondary category of Arxiv papers based on the titles and abstracts",
    "ArxivClusteringS2S": "Identify the main and secondary category of Arxiv papers based on the titles",
    "BiorxivClusteringP2P": "Identify the main category of Biorxiv papers based on the titles and abstracts",
    "BiorxivClusteringS2S": "Identify the main category of Biorxiv papers based on the titles",
    "MedrxivClusteringP2P": "Identify the main category of Medrxiv papers based on the titles and abstracts",
    "MedrxivClusteringS2S": "Identify the main category of Medrxiv papers based on the titles",
    "RedditClustering": "Identify the topic or theme of Reddit posts based on the titles",
    "RedditClusteringP2P": "Identify the topic or theme of Reddit posts based on the titles and posts",
    "StackExchangeClustering": "Identify the topic or theme of StackExchange posts based on the titles",
    "StackExchangeClusteringP2P": "Identify the topic or theme of StackExchange posts based on the given paragraphs",
    "TwentyNewsgroupsClustering": "Identify the topic or theme of the given news articles",
    "CLSClusteringS2S": "Identify the main category of scholar papers based on the titles",
    "CLSClusteringP2P": "Identify the main category of scholar papers based on the titles and abstracts",
    "ThuNewsClusteringS2S": "Identify the topic or theme of the given news articles based on the titles",
    "ThuNewsClusteringP2P": "Identify the topic or theme of the given news articles based on the titles and contents",
    "AskUbuntuDupQuestions": "Retrieve duplicate questions from AskUbuntu forum",
    "MindSmallReranking": "Retrieve relevant news articles based on user browsing history",
    "SciDocsRR": "Given a title of a scientific paper, retrieve the titles of other relevant papers",
    "StackOverflowDupQuestions": "Retrieve duplicate questions from StackOverflow forum",
    "SprintDuplicateQuestions": "Retrieve duplicate questions from Sprint forum",
    "TwitterSemEval2015": "Retrieve tweets that are semantically similar to the given tweet",
    "T2Reranking": "Given a Chinese search query, retrieve web passages that answer the question",
    "CMedQAv1": "Given a Chinese community medical question, retrieve replies that best answer the question",
    "Ocnli": "Retrieve semantically similar text.",
    "ArguAna": "Given a claim, find documents that refute the claim",
    "ClimateFEVER": "Given a claim about climate change, retrieve documents that support or refute the claim",
    "DBPedia": "Given a query, retrieve relevant entity descriptions from DBPedia",
    "FEVER": "Given a claim, retrieve documents that support or refute the claim",
    "FiQA2018": "Given a financial question, retrieve user replies that best answer the question",
    "HotpotQA": "Given a multi-hop question, retrieve documents that can help answer the question",
    "MSMARCO": "Given a web search query, retrieve relevant passages that answer the query",
    "NFCorpus": "Given a question, retrieve relevant documents that best answer the question",
    "NQ": "Given a question, retrieve Wikipedia passages that answer the question",
    "QuoraRetrieval": "Given a question, retrieve questions that are semantically equivalent to the given question",
    "SCIDOCS": "Given a scientific paper title, retrieve paper abstracts that are cited by the given paper",
    "SciFact": "Given a scientific claim, retrieve documents that support or refute the claim",
    "Touche2020": "Given a question, retrieve detailed and persuasive arguments that answer the question",
    "TRECCOVID": "Given a query on COVID-19, retrieve documents that answer the query",
    "CovidRetrieval": "Given a question on COVID-19, retrieve news articles that answer the question",
    "EcomRetrieval": "Given a user query from an e-commerce website, retrieve description sentences of relevant products",
    "MedicalRetrieval": "Given a medical question, retrieve user replies that best answer the question",
    "VideoRetrieval": "Given a video search query, retrieve the titles of relevant videos",
    "STSBenchmarkMultilingualSTS": "Retrieve semantically similar text",
    "SummEvalFr": "Given a news summary, retrieve other semantically similar summaries",
    "MasakhaNEWSClassification": "Classify the News in the given texts into one of the seven category: politics,sports,health,business,entertainment,technology,religion",
    "AlloProfClusteringP2P": "Identify the main category of Allo Prof document based on the titles and descriptions",
    "AlloProfClusteringS2S": "Identify the main category of Allo Prof document based on the titles",
    "HALClusteringS2S": "Identify the main category of academic passage based on the titles and contents",
    "MLSUMClusteringP2P": "Identify the topic or theme of the given articles based on the titles and contents",
    "MLSUMClusteringS2S": "Identify the topic or theme of the given articles based on the titles",
    "SyntecReranking": "Given a question, retrieve passages that answer the question",
    "CBD": "Classify the sentiment of polish tweet reviews",
    "PolEmo2.0-IN": "Classify the sentiment of in-domain (medicine and hotels) online reviews",
    "PolEmo2.0-OUT": "Classify the sentiment of out-of-domain (products and school) online reviews",
    "AllegroReviews": "Classify the sentiment of reviews from e-commerce marketplace Allegro",
    "PAC": "Classify the sentence into one of the two types: \"BEZPIECZNE_POSTANOWIENIE_UMOWNE\" and \"KLAUZULA_ABUZYWNA\"",
    "8TagsClustering": "Identify of headlines from social media posts in Polish  into 8 categories: film, history, food, medicine, motorization, work, sport and technology",
    "GeoreviewClassification": "Classify the organization rating based on the reviews",
    "HeadlineClassification": "Classify the topic or theme of the given news headline",
    "InappropriatenessClassification": "Classify the given message as either sensitive topic or not",
    "KinopoiskClassification": "Classify the sentiment expressed in the given movie review text",
    "RuReviewsClassification": "Classify product reviews into positive, negative or neutral sentiment",
    "RuSciBenchGRNTIClassification": "Classify the category of scientific papers based on the titles and abstracts",
    "GeoreviewClusteringP2P": "Identify the organization category based on the reviews",
    "RuSciBenchGRNTIClusteringP2P": "Identify the category of scientific papers based on the titles and abstracts",
    "TERRa": "Given a premise, retrieve a hypothesis that is entailed by the premise",
    "RiaNewsRetrieval": "Given a headline, retrieval relevant articles",
    "AppsRetrieval": "Given a question about code problem, retrieval code that can solve user's problem",
    "COIRCodeSearchNetRetrieval": "Given a code snippet, retrieve the comment corresponding to that code.",
    "CodeEditSearchRetrieval": "Given a piece of code, retrieval code that in the",
    "CodeFeedbackMT": "Given a question about coding, retrieval code or passage that can solve user's question",
    "CodeSearchNetCCRetrieval": "Given a code comment, retrieve the code snippet corresponding to that comment.",
    "CodeTransOceanContest": "Given a piece for code, retrieval semantically similar code",
    "SyntheticText2SQL": "Given a user's question, retrieve SQL queries that are appropriate responses to the question",
    "BibleNLPBitextMining": "Retrieve parallel sentences",
    "BulgarianStoreReviewSentimentClassfication": "Classify user reviews into positive or negative sentiment",
    "CzechProductReviewSentimentClassification": "Classify product reviews into positive or negative sentiment",
    "GreekLegalCodeClassification": "Given a greek legal text, classify its topic",
    "DBpediaClassification": "Given a Wikipedia articles, categorized it into classes based on its DBpedia ontology",
    "FinancialPhrasebankClassification": "Given financial news, categorized by sentiment into positive, negative, or neutral",
    "PoemSentimentClassification": "Gvien a poem, categorized by sentiment into positive, no_impact, negative or mixed",
    "TweetTopicSingleClassification": "Gvien a twitter, classify its topic",
    "EstonianValenceClassification": "Given a news article, categorized by sentiment into negatiivne, positiivne, neutraalne or vastuolulin",
    "FilipinoShopeeReviewsClassification": "Given a shop review, classify its rating on a scale from 1 to 5",
    "GujaratiNewsClassification": "Given a Gujarati news articles, classify ist topic",
    "SentimentAnalysisHindi": "Given a hindi text, categorized by sentiment into positive, negative or neutral",
    "IndonesianIdClickbaitClassification": "Given an Indonesian news headlines, classify its into clickbait or non-clickbait",
    "ItaCaseholdClassification": "Given a judgments, classify its topic",
    "KorSarcasmClassification": "Given a twitter, categorized it into sarcasm or not_sarcasm",
    "KurdishSentimentClassification": "Given a text, categorized by sentiment into positive or negative",
    "MacedonianTweetSentimentClassification": "Given a Macedonian tweet, categorized by sentiment into positive, negative, or neutral",
    "AfriSentiClassification": "Given a text, categorized by sentiment into positive, negative, or neutral",
    "CataloniaTweetClassification": "Given a tweet, categorized by sentiment into AGAINST, FAVOR or NEUTRAL",
    "CyrillicTurkicLangClassification": "Given a text, classify its language",
    "MultiHateClassification": "Given a text, categorized by sentiment into hate or non-hate",
    "NusaParagraphEmotionClassification": "Given a paragraph, classify its emotion",
    "SwissJudgementClassification": "Given a news article, categorized it into approval or dismissal",
    "NepaliNewsClassification": "Given a news article, categorized it into business, entertainment or sports",
    "PunjabiNewsClassification": "Given a news article, categorized it into two-classes",
    "SinhalaNewsClassification": "Given a news article, categorized it into political, business, technology, sports and Entertainment",
    "CSFDSKMovieReviewSentimentClassification": "Given a movie review, classify its rating on a scale from 0 to 5",
    "SiswatiNewsClassification": "Given a news article, classify its topic",
    "SlovakMovieReviewSentimentClassification": "Given a movie review, categorized it into positive or negative",
    "SwahiliNewsClassification": "Given a news article, classify its domain",
    "WikiCitiesClustering": "Identify of Wikipedia articles of cities by country",
    "RomaniBibleClustering": "Identify verses from the Bible in Kalderash Romani by book.",
    "BigPatentClustering.v2": "Identify the category of documents from the Big Patent dataset",
    "AlloProfClusteringS2S.v2": "Identify the topic of document titles from Allo Prof dataset",
    "HALClusteringS2S.v2": "Identify the topic of titles from HAL",
    "SIB200ClusteringS2S": "Identify the category of documents",
    "WikiClusteringP2P.v2": "Identify the category of wiki passages",
    "PlscClusteringP2P.v2": "Identify the category of titles+abstracts from Library of Science",
    "KorHateSpeechMLClassification": "Given a Korean online news comments, classify its fine-grained hate speech classes",
    "MalteseNewsClassification": "Given a maltese new, classify its topic",
    "MultiEURLEXMultilabelClassification": "Given a text, classify its topic",
    "BrazilianToxicTweetsClassification": "Given a tweet, classify its topic",
    "AILAStatutes": "Identifying the most relevant statutes for a given situation",
    "HagridRetrieval": "Retrieval the relevant passage for the given query",
    "MIRACLRetrievalHardNegatives": "Retrieval relevant passage for the given query",
    "CQADupstackRetrieval": "Given a question, retrieve detailed question descriptions from Stackexchange that are duplicates to the given question"
}

CUSTOM_PROMPTS = {
    "NoInstruction": "",
    "CustomEng1": "Given a news title, retrieve the article corresponding to it",
    "CustomEng2": "Given a news title, retrieve the article that is the correct pair for the given title",
    "CustomEng3": "Given a news title, retrieve the article that best corresponds to the given title",
    "CustomEng4": "Retrieve the relevant article for the given news title",
    "CustomFin1": "Hae uutisotsikkoa vastaava artikkeli",
    "CustomFin2": "Hae oikea artikkeli, joka kuuluu seuraavalle uutisotsikolle",
    "CustomFin3": "Löydä seuraavalle uutisotsikolle kuuluva artikkeli"
    }

MTEB_PROMPTS = {
    "BitextMining": {
        "NorwegianCourtsBitextMining": "Retrieve parallel sentences in Norwegian Bokmål and Nynorsk",
        "BornholmBitextMining": "Retrieve parallel sentences."
    },
    "Classification": {
        "HUMEEmotionClassification": "Classify the emotion expressed in the given Twitter message into one of the six emotions: anger, fear, joy, love, sadness, and surprise",
        "HUMEToxicConversationsClassification": "Classify the given comments as either toxic or not toxic",
        "InappropriatenessClassificationv2": "Classify the given message as either sensitive topic or not",
        "HUMETweetSentimentExtractionClassification": "Classify the sentiment of a given tweet as either positive, negative, or neutral",
        "FaIntentClassification": "Classify user passages."
    },
    "Clustering": {
        "HUMEWikiCitiesClustering": "Identify categories in user passages.",
        "HUMEArxivClusteringP2P": "Identify the main and secondary category of Arxiv papers based on the titles and abstracts",
        "HUMESIB200ClusteringS2S": "Identify the news category that articles belong to based on their content",
        "HUMERedditClusteringP2P": "Identify the topic or theme of Reddit posts based on the titles and posts",
        "KlueYnatMrcCategoryClustering": "Identify the topic or theme of the given texts"
    },
    "InstructionReranking": {
        "Core17InstructionRetrieval": "Retrieve text based on user query."
    },
    "PairClassification": {
        "TERRa": "Given a premise, retrieve a hypothesis that is entailed by the premise",
        "SprintDuplicateQuestions": "Retrieve duplicate questions from Sprint forum",
        "Cmnli": "Retrieve semantically similar text.",
        "ArEntail": "Retrieve text that are semantically similar to the given text.",
        "TwitterSemEval2015": "Retrieve tweets that are semantically similar to the given tweet"
    },
    "Reranking": {
        "CMedQAv1-reranking": "Given a Chinese community medical question, retrieve replies that best answer the question",
        "MMarcoReranking": "Given a Chinese search query, retrieve web passages that answer the question",
        "JQaRAReranking": "Given a Japanese question, rerank passages based on their relevance for answering the question",
        "VoyageMMarcoReranking": "Given a Japanese search query, retrieve web passages that answer the question",
        "LocBenchRR": "Given a github issue, identify the code that needs to be changed to fix the issue.",
        "HUMEWikipediaRerankingMultilingual": "Given a query, rerank the Wikipedia passages by their relevance to the query",
        "HUMECore17InstructionReranking": "Given a query, rerank the documents by their relevance to the query",
        "BuiltBenchReranking": "Given a query, retrieve relevant entity descriptions from buit asset classification systems such as IFC and Uniclass",
        "MIRACLReranking": "Given a question, retrieve Wikipedia passages that answer the question",
        "RuBQReranking": "Given a question, retrieve Wikipedia passages that answer the question.",
        "SciDocsRR": "Given a title of a scientific paper, retrieve the titles of other relevant papers",
        "AskUbuntuDupQuestions": "Retrieve duplicate questions from AskUbuntu forum",
        "StackOverflowDupQuestions": "Retrieve duplicate questions from StackOverflow forum",
        "MindSmallReranking": "Retrieve relevant news articles based on user browsing history"
    },
    "Retrieval": {
        "SwednRetrieval": "Given a Swedish news headline retrieve summaries or news articles",
        "ClimateFEVER": "Given a claim about climate change, retrieve documents that support or refute the claim",
        "DanFeverRetrieval": "Given a claim in Danish, retrieve documents that support the claim",
        "ArguAna": "Given a claim, find documents that refute the claim",
        "FEVER": "Given a claim, retrieve documents that support or refute the claim",
        "FinQARetrieval": "Given a financial numerical reasoning question, retrieve relevant financial data that helps answer the question",
        "HC3FinanceRetrieval": "Given a financial question or prompt, retrieve relevant financial content that best addresses the query",
        "FinanceBenchRetrieval": "Given a financial question, retrieve relevant financial information that best answers the question",
        "FiQA2018": "Given a financial question, retrieve user replies that best answer the question",
        "SNLRetrieval": "Given a lexicon headline in Norwegian, retrieve its article",
        "BIRCO-Relic": "Given a literary analysis with a missing quotation (marked as [masked sentence(s)]), retrieve the passage that best completes the analysis.",
        "ChatDoctorRetrieval": "Given a medical question from a patient, retrieve relevant healthcare information that best answers the question",
        "MedicalRetrieval": "Given a medical question, retrieve user replies that best answer the question",
        "HotpotQA": "Given a multi-hop question, retrieve documents that can help answer the question",
        "RiaNewsRetrieval": "Given a news title, retrieve relevant news article",
        "BIRCO-ArguAna": "Given a one-paragraph argument, retrieve the passage that contains the counter-argument which directly refutes the query's stance.",
        "BIRCO-ClinicalTrial": "Given a patient case report, retrieve the clinical trial description that best matches the patient's eligibility criteria.",
        "TRECCOVID": "Given a query on COVID-19, retrieve documents that answer the query",
        "DBPedia": "Given a query, retrieve relevant entity descriptions from DBPedia",
        "CUREv1": "Given a question by a medical professional, retrieve relevant passages that best answer the question",
        "NorQuadRetrieval": "Given a question in Norwegian, retrieve the answer from Wikipedia articles",
        "CovidRetrieval": "Given a question on COVID-19, retrieve news articles that answer the question",
        "NanoTouche2020Retrieval": "Given a question, retrieve detailed and persuasive arguments that answer the question",
        "NanoQuoraRetrieval": "Given a question, retrieve questions that are semantically equivalent to the given question",
        "NFCorpus": "Given a question, retrieve relevant documents that best answer the question",
        "NanoSciFactRetrieval": "Given a scientific claim, retrieve documents that support or refute the claim",
        "SCIDOCS": "Given a scientific paper title, retrieve paper abstracts that are cited by the given paper",
        "TV2Nordretrieval": "Given a summary of a Danish news article retrieve the corresponding news article",
        "RuSciBenchCiteRetrieval": "Given a title and abstract of a scientific paper, retrieve the titles and abstracts of other relevant papers",
        "EcomRetrieval": "Given a user query from an e-commerce website, retrieve description sentences of relevant products",
        "VideoRetrieval": "Given a video search query, retrieve the titles of relevant videos",
        "MSMARCO": "Given a web search query, retrieve relevant passages that answer the query",
        "BIRCO-WTB": "Given an ambiguous description of a book, retrieve the book description that best matches the query.",
        "SIQA": "Given the following context and question, retrieve the correct answer.",
        "PIQA": "Given the following goal, retrieve a possible solution.",
        "TempReasonL1": "Given the following question about time, retrieve the correct answer.",
        "TempReasonL2Fact": "Given the following question and facts, retrieve the correct answer.",
        "TempReasonL2Context": "Given the following question, facts and contexts, retrieve the correct answer.",
        "TempReasonL2Pure": "Given the following question, retrieve the correct answer.",
        "WinoGrande": "Given the following sentence, retrieve an appropriate answer to fill in the missing underscored part.",
        "SpartQA": "Given the following spatial reasoning question, retrieve the right answer.",
        "AlphaNLI": "Given the following start and end of a story, retrieve a possible reason that leads to the end.",
        "HellaSwag": "Given the following unfinished context, retrieve the most plausible ending to finish it.",
        "BIRCO-DorisMae": "Identify scientific abstracts that fulfill research requirements",
        "SweFaqRetrieval": "Retrieve answers given questions in Swedish",
        "TwitterHjerneRetrieval": "Retrieve answers to questions asked in Danish tweets",
        "RARbCode": "Retrieve the answer for the following coding problem.",
        "RARbMath": "Retrieve the answer for the following math problem.",
        "ARCChallenge": "Retrieve the answer to the question."
    },
    "Any2AnyRetrieval": {
        "WebQAT2TRetrieval": "Retrieve passages from Wikipedia that provide answers to the following question."
    },
    "Summarization": {
        "SummEvalSummarization.v2": "Given a news summary, retrieve other semantically similar summaries."
    }
}

def flatten_mteb_prompts():
    return {k: v for inner in MTEB_PROMPTS.values() for k, v in inner.items()}

MTEB_PROMPTS_FLAT = flatten_mteb_prompts()